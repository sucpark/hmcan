{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HMCAN Training on Google Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sucpark/hmcan/blob/main/notebooks/train_hmcan_colab.ipynb)\n",
        "\n",
        "Hierarchical Multichannel CNN-based Attention Network for Document Classification\n",
        "\n",
        "## Phase 1: Foundation Models (HAN, HCAN, HMCAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/sucpark/hmcan.git\n",
        "%cd hmcan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -e . -q\n",
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Weights & Biases Setup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to wandb (optional but recommended)\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Yelp dataset and GloVe embeddings\n",
        "# --max-samples: Number of samples to use (reduce for faster experiments)\n",
        "!python scripts/download_data.py --max-samples 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View default HMCAN config\n",
        "!cat configs/hmcan.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modify config if needed (enable wandb)\n",
        "import yaml\n",
        "\n",
        "with open('configs/hmcan.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Enable wandb logging\n",
        "config['use_wandb'] = True\n",
        "config['use_tensorboard'] = True\n",
        "\n",
        "# Save modified config\n",
        "with open('configs/hmcan_colab.yaml', 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(\"Config saved to configs/hmcan_colab.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Train HMCAN (Main Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m hmcan train --config configs/hmcan_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Train HAN (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modify HAN config for wandb\n",
        "with open('configs/han.yaml', 'r') as f:\n",
        "    han_config = yaml.safe_load(f)\n",
        "\n",
        "han_config['use_wandb'] = True\n",
        "han_config['use_tensorboard'] = True\n",
        "\n",
        "with open('configs/han_colab.yaml', 'w') as f:\n",
        "    yaml.dump(han_config, f, default_flow_style=False)\n",
        "\n",
        "!python -m hmcan train --config configs/han_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Train HCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modify HCAN config for wandb\n",
        "with open('configs/hcan.yaml', 'r') as f:\n",
        "    hcan_config = yaml.safe_load(f)\n",
        "\n",
        "hcan_config['use_wandb'] = True\n",
        "hcan_config['use_tensorboard'] = True\n",
        "\n",
        "with open('configs/hcan_colab.yaml', 'w') as f:\n",
        "    yaml.dump(hcan_config, f, default_flow_style=False)\n",
        "\n",
        "!python -m hmcan train --config configs/hcan_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate HMCAN\n",
        "!python -m hmcan evaluate --checkpoint outputs/hmcan_yelp/checkpoints/best_model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate HAN\n",
        "!python -m hmcan evaluate --checkpoint outputs/han_yelp/checkpoints/best_model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate HCAN\n",
        "!python -m hmcan evaluate --checkpoint outputs/hcan_yelp/checkpoints/best_model.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy outputs to Drive\n",
        "!cp -r outputs /content/drive/MyDrive/hmcan_outputs\n",
        "print(\"Outputs saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "models = ['han', 'hcan', 'hmcan']\n",
        "results = {}\n",
        "\n",
        "for model in models:\n",
        "    ckpt_path = f'outputs/{model}_yelp/checkpoints/best_model.pt'\n",
        "    if os.path.exists(ckpt_path):\n",
        "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "        results[model] = ckpt.get('metrics', {})\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Results Summary\")\n",
        "print(\"=\" * 50)\n",
        "for model, metrics in results.items():\n",
        "    acc = metrics.get('accuracy', 'N/A')\n",
        "    if isinstance(acc, float):\n",
        "        acc = f\"{acc*100:.2f}%\"\n",
        "    print(f\"{model.upper():8s}: {acc}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Attention Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from hmcan.models import HMCAN\n",
        "from hmcan.data import YelpDataModule\n",
        "\n",
        "# Load data\n",
        "data_module = YelpDataModule(data_dir='data')\n",
        "data_module.setup()\n",
        "\n",
        "# Load model\n",
        "model = HMCAN(\n",
        "    vocab_size=len(data_module.vocabulary),\n",
        "    pretrained_embeddings=data_module.pretrained_embeddings,\n",
        ")\n",
        "ckpt = torch.load('outputs/hmcan_yelp/checkpoints/best_model.pt', map_location='cpu')\n",
        "model.load_state_dict(ckpt['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a sample and visualize attention\n",
        "test_loader = data_module.test_dataloader()\n",
        "batch = next(iter(test_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(batch['document'], batch['sentence_lengths'])\n",
        "\n",
        "# Sentence attention visualization\n",
        "sent_attn = outputs['sentence_attention'].squeeze().numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(range(len(sent_attn)), sent_attn)\n",
        "plt.xlabel('Sentence Index')\n",
        "plt.ylabel('Attention Weight')\n",
        "plt.title('Sentence-level Attention Weights')\n",
        "plt.tight_layout()\n",
        "plt.savefig('sentence_attention.png', dpi=150)\n",
        "plt.show()"
      ]
    }
  ]
}
