{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMCAN Training (VS Code + Colab Extension)\n",
    "\n",
    "Hierarchical Multichannel CNN-based Attention Network for Document Classification\n",
    "\n",
    "## Phase 1: Foundation Models (HAN, HCAN, HMCAN)\n",
    "\n",
    "**Compatible with VS Code Colab Extension**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/sucpark/hmcan.git\"\n",
    "PROJECT_DIR = \"/content/hmcan\"\n",
    "\n",
    "if os.path.exists(PROJECT_DIR):\n",
    "    print(\"Updating existing project...\")\n",
    "    %cd {PROJECT_DIR}\n",
    "    !git pull\n",
    "else:\n",
    "    print(\"Cloning project...\")\n",
    "    !git clone {REPO_URL} {PROJECT_DIR}\n",
    "    %cd {PROJECT_DIR}\n",
    "\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e . -q\n",
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "**WandB Options:**\n",
    "- Set `USE_WANDB = True` and provide API key for logging\n",
    "- Set `USE_WANDB = False` to disable (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "USE_WANDB = False  # Set True to enable WandB logging\n",
    "WANDB_API_KEY = \"\"  # Paste your API key here if using WandB\n",
    "\n",
    "# WandB setup (programmatic login - no interactive prompt)\n",
    "if USE_WANDB and WANDB_API_KEY:\n",
    "    import wandb\n",
    "    wandb.login(key=WANDB_API_KEY)\n",
    "    print(\"WandB logged in successfully!\")\n",
    "elif USE_WANDB:\n",
    "    print(\"Warning: USE_WANDB=True but no API key provided. WandB will be disabled.\")\n",
    "    USE_WANDB = False\n",
    "else:\n",
    "    print(\"WandB disabled. Using TensorBoard only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Yelp dataset and GloVe embeddings\n",
    "# --max-samples: Number of samples to use (reduce for faster experiments)\n",
    "!python scripts/download_data.py --max-samples 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Create configs for each model with current settings\n",
    "for model_name in ['hmcan', 'han', 'hcan']:\n",
    "    config_path = f'configs/{model_name}.yaml'\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Set logging options\n",
    "    config['use_wandb'] = USE_WANDB\n",
    "    config['use_tensorboard'] = True\n",
    "    \n",
    "    # Save modified config\n",
    "    colab_config_path = f'configs/{model_name}_colab.yaml'\n",
    "    with open(colab_config_path, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Created {colab_config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train HMCAN (Main Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m hmcan train --config configs/hmcan_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train HAN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m hmcan train --config configs/han_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Train HCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m hmcan train --config configs/hcan_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate HMCAN\n",
    "!python -m hmcan evaluate --checkpoint outputs/hmcan_yelp/checkpoints/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate HAN\n",
    "!python -m hmcan evaluate --checkpoint outputs/han_yelp/checkpoints/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate HCAN\n",
    "!python -m hmcan evaluate --checkpoint outputs/hcan_yelp/checkpoints/best_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "models = ['han', 'hcan', 'hmcan']\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    ckpt_path = f'outputs/{model}_yelp/checkpoints/best_model.pt'\n",
    "    if os.path.exists(ckpt_path):\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        results[model] = ckpt.get('metrics', {})\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Results Summary\")\n",
    "print(\"=\" * 50)\n",
    "for model, metrics in results.items():\n",
    "    acc = metrics.get('accuracy', 'N/A')\n",
    "    if isinstance(acc, float):\n",
    "        acc = f\"{acc*100:.2f}%\"\n",
    "    print(f\"{model.upper():8s}: {acc}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results (Git Push)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files have changed\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save results to GitHub\n",
    "# !git add outputs/\n",
    "# !git commit -m \"Add training results from Colab\"\n",
    "# !git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Attention Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from hmcan.models import HMCAN\n",
    "from hmcan.data import YelpDataModule\n",
    "\n",
    "# Load data\n",
    "data_module = YelpDataModule(data_dir='data')\n",
    "data_module.setup()\n",
    "\n",
    "# Load model\n",
    "model = HMCAN(\n",
    "    vocab_size=len(data_module.vocabulary),\n",
    "    pretrained_embeddings=data_module.pretrained_embeddings,\n",
    ")\n",
    "ckpt = torch.load('outputs/hmcan_yelp/checkpoints/best_model.pt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample and visualize attention\n",
    "test_loader = data_module.test_dataloader()\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch['document'], batch['sentence_lengths'])\n",
    "\n",
    "# Sentence attention visualization\n",
    "sent_attn = outputs['sentence_attention'].squeeze().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(len(sent_attn)), sent_attn)\n",
    "plt.xlabel('Sentence Index')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.title('Sentence-level Attention Weights')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentence_attention.png', dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
